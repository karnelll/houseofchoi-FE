import { useCallback, useRef } from "react";
// @ts-expect-error: RecorderëŠ” íƒ€ì… ì •ì˜ê°€ ì—†ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
import Recorder from "recorder-js";
import { fetchSpeechToText } from "@/apis/chatbot/stt";
import { STTResponse } from "@/types/chatbot";

export function useVoiceRecorder() {
  const recorderRef = useRef<Recorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const isRecordingRef = useRef<boolean>(false);
  const isCancelledRef = useRef<boolean>(false);

  const stopAndProcess = async (
    onComplete: (blob: Blob, transcript: string) => void,
    isCancelled: boolean = false,
  ) => {
    if (!isRecordingRef.current) return;
    isRecordingRef.current = false;

    try {
      const recorder = recorderRef.current;
      const stream = streamRef.current;

      if (!recorder || !stream) return;

      const { blob } = await recorder.stop();
      stream.getTracks().forEach((track) => track.stop());

      console.log("ğŸ§ ë…¹ìŒëœ íŒŒì¼:", blob);

      if (isCancelled) {
        console.log("ğŸ›‘ STT API í˜¸ì¶œì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.");
        onComplete(new Blob(), "");
        return;
      }

      const transcript: STTResponse = await fetchSpeechToText(blob);
      console.log("ğŸ“ STT ì‘ë‹µ ê²°ê³¼:", transcript);

      const text = transcript?.user_message ?? "";
      console.log("ğŸ—£ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼:", text);

      onComplete(blob, typeof text === "string" ? text : "");
      console.log("âœ… onComplete í˜¸ì¶œ ì™„ë£Œ");
    } catch (err: unknown) {
      if (err instanceof Error) {
        console.error("âŒ ë…¹ìŒ ì²˜ë¦¬ ì‹¤íŒ¨:", err.message);
      } else {
        console.error("âŒ ë…¹ìŒ ì²˜ë¦¬ ì‹¤íŒ¨: ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ");
      }
      onComplete(new Blob(), "");
    }
  };

  const startRecording = useCallback(
    async (onComplete: (blob: Blob, transcript: string) => void) => {
      try {
        isCancelledRef.current = false;
        const stream: MediaStream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });

        const audioContext = new (window.AudioContext ||
          (
            window as Window &
              typeof globalThis & { webkitAudioContext: typeof AudioContext }
          ).webkitAudioContext)();

        const recorder = new Recorder(audioContext);
        await recorder.init(stream);

        recorderRef.current = recorder;
        streamRef.current = stream;
        isRecordingRef.current = true;

        recorder.start();
        console.log("ğŸ™ï¸ ë…¹ìŒ ì‹œì‘");

        setTimeout(() => {
          stopAndProcess(onComplete, isCancelledRef.current);
        }, 6000);
      } catch (err: unknown) {
        if (err instanceof Error) {
          console.error("âŒ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:", err.message);
        } else {
          console.error("âŒ ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨: ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ");
        }
      }
    },
    [],
  );

  const stopRecording = useCallback(
    (
      onComplete: (blob: Blob, transcript: string) => void,
      isCancelled: boolean = false,
    ) => {
      if (!isRecordingRef.current) return;
      isCancelledRef.current = isCancelled;
      stopAndProcess(onComplete, isCancelled);
    },
    [],
  );

  return {
    startRecording,
    stopRecording,
  };
}
